{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tNtORVaGbgml"
   },
   "source": [
    "Data Science Challenge\n",
    "\n",
    "The dataset you are given contains matches of a MOBA game. The matches are uniquely identified by a `match_id`. Per match, there are several rows. Each row describes a unique gamestate in the match. We have removed the names of the other columns.\n",
    "\n",
    "Your task is to produce a model that predicts the `winner` of the match given a particular gamestate. The winner may be the \"home\" team (`0`) or the away team (`1`). Please, bear in mind that the trained model would be used to produce live-odds while a game is being played, i.e. it would have to continuosly update the probability of each team winning, based on the game played so far.\n",
    "\n",
    "The data is challenge_data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tesse\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=0.01975817364568719, intercept=47.45521868871651, rvalue=0.2912827466638715, pvalue=0.03809694844912819, stderr=0.00927003072712697)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# feel free to change the variable name to something you are comfortable with\n",
    "df = pd.read_csv(\"challenge_data.csv\")\n",
    "# some basic libraries\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'k' \n",
    "\n",
    "# remove index col\n",
    "del df[\"Unnamed: 0\"]\n",
    "# no null vals, one \"catch me if you can\" will be filled\n",
    "df[\"feature_4\"].loc[df[\"feature_4\"] == \"catch me if you can\"] = 5845.0\n",
    "\n",
    "# ok, so, what do we have is a list of games played between two player\n",
    "# we suppose two-same players because otherwise we wold have to know \n",
    "# a sort of identification for each player to be able to take it into \n",
    "# account, since we don't, we will consider all these games were played\n",
    "# between two team at different times\n",
    "# therefore each match is a trial - a sample\n",
    "\n",
    "# it is a semi-structured database with different recorded-times, but \n",
    "# they seem to have a pattern, next iteration increases roughly by 20 seconds\n",
    "\n",
    "# get rid of - values in winner column\n",
    "df.drop(df[df[\"winner\"] == -1.0].index, inplace=True)\n",
    "\n",
    "# convert the feature_4 column to floats\n",
    "df = df.astype({\"feature_4\": float})\n",
    "\n",
    "# get match ids in a list\n",
    "match_ids = df[\"match_id\"].unique()\n",
    "\n",
    "## we will do the training for a specific time interval\n",
    "# for single time interval\n",
    "# x -> feat_1, feat_2, feat_3, feat_4\n",
    "# y -> winner\n",
    "\n",
    "# stats box to hold statistic results\n",
    "stats_box = []\n",
    "# verbosity for individual predictions\n",
    "talkative = False\n",
    "# methods to train, forest -> random forest classification (of sklearn), nn -> neural network (keras implemenation)\n",
    "training = \"forest\" # NOTE: nn doesn't work\n",
    "\n",
    "#iterate through the game_time_id(s) and collect accuracies for each id\n",
    "# each 20 secs, get the approximate max id\n",
    "for game_time_id in range(round(max(df[\"game_time\"])/20)):\n",
    "    # boxes for features and labels\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # creates X, y for all matches, for one time interval\n",
    "    # quick intuition about the features, feat_4 seems to be linear\n",
    "    # feat_3 barely changes and change doesn't seem significant\n",
    "    # keep feat_1 and feat_2\n",
    "\n",
    "    for match_id in match_ids:\n",
    "        try:\n",
    "            match = df[df[\"match_id\"] == match_id].iloc[game_time_id]\n",
    "            X.append(list(match[3:5])) # freature columns\n",
    "            y.append(match[2])  # label - winner column value\n",
    "        # game end times differ, in case game ended shortly, catch error\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # some datasets will be so small, splitting them will raise error\n",
    "    try:\n",
    "        # train/test split\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        \n",
    "        if talkative:\n",
    "            # some stats\n",
    "            print(\"time int: \", (game_time_id +3)*20)\n",
    "            print(\"total X/y: \", len(X))\n",
    "            print(\"total X_train/y_train: \", len(X_train))\n",
    "            print(\"total X_test/y_test: \", len(X_test))\n",
    "\n",
    "        # without tuning, without actually thinking\n",
    "        # training\n",
    "        if training == \"forest\":\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            regressor = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "            regressor.fit(X_train, y_train)\n",
    "            y_pred = regressor.predict(X_test)\n",
    "\n",
    "            # metrics\n",
    "            from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            if talkative:\n",
    "                print(confusion_matrix(y_test,y_pred))\n",
    "                print(classification_report(y_test,y_pred))\n",
    "                print(acc)\n",
    "                  \n",
    "        elif training == \"nn\":\n",
    "            # some sets are so small layers can't work on them\n",
    "            # need smarter layer handling, failed!\n",
    "            try:\n",
    "                # NN approach, architecture copied form machine learning mastery webiste\n",
    "                # first neural network with keras tutorial\n",
    "                from numpy import loadtxt\n",
    "                from keras.models import Sequential\n",
    "                from keras.layers import Dense\n",
    "\n",
    "                # conv to np arrays as tf requires\n",
    "                X = np.array(X)\n",
    "                y = np.array(y)\n",
    "\n",
    "                # define the keras model\n",
    "                model = Sequential()\n",
    "                model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "                model.add(Dense(4, activation='relu'))\n",
    "                model.add(Dense(1, activation='sigmoid'))\n",
    "                # compile the keras model\n",
    "                model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "                # fit the keras model on the dataset\n",
    "                model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
    "                # evaluate the keras model\n",
    "                _, acc = model.evaluate(X, y, verbose=0)\n",
    "            except Exception as e:\n",
    "                acc = 0\n",
    "        else:\n",
    "            print(\"please choose a training method above\")            \n",
    "\n",
    "    # catch them errors\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    # collect info - > game_time, total samples, training samples, test samples, accuracy\n",
    "    stats_box.append([(game_time_id +3)*20, len(X), len(X_train), len(X_test), acc*100])\n",
    "    \n",
    "# stats_box to dataframe\n",
    "df1 = pd.DataFrame(stats_box)\n",
    "df1.columns = [\"time\",\"total\",\"train\",\"test\",\"acc\"]\n",
    "df1[[\"total\",\"train\",\"test\",\"acc\"]].plot()\n",
    "\n",
    "# intuitively towards the end of the game it must be easier to predict the winner\n",
    "# very last predictions since there are less samples, predictions don't make sense\n",
    "# overall it doesn't seem to learn a lot, further feature engineering is needed\n",
    "\n",
    "# at least the slope is bigger than 0, I know this is so cheap...\n",
    "from scipy.stats import linregress\n",
    "linregress(df1[\"time\"], df1[\"acc\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "bayes_ds_challenge.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
